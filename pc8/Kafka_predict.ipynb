{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBd52sqKxpL9Vihd2+OvSW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomasKricka/MPA-MLF/blob/main/pc8/Kafka_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "plAw5WtzH5zc"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O kafka_Metamorphosis.txt https://www.gutenberg.org/files/5200/5200-0.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53SHm6m2KnNc",
        "outputId": "db8e584f-4b4f-4406-aa5e-11b29ba8a2d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-06 06:41:15--  https://www.gutenberg.org/files/5200/5200-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 142017 (139K) [text/plain]\n",
            "Saving to: ‘kafka_Metamorphosis.txt’\n",
            "\n",
            "kafka_Metamorphosis 100%[===================>] 138.69K   816KB/s    in 0.2s    \n",
            "\n",
            "2023-04-06 06:41:15 (816 KB/s) - ‘kafka_Metamorphosis.txt’ saved [142017/142017]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('kafka_Metamorphosis.txt', 'r').read().lower()\n",
        "print('text lenght: ', len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX93fiPNLe6U",
        "outputId": "71543143-7e0b-453c-f7d7-00fe289a56b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text lenght:  138408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-evvU_SL9Tw",
        "outputId": "7a21525e-b532-40db-d237-f4f07554cfbf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿the project gutenberg ebook of metamorphosis, by franz kafka\n",
            "\n",
            "this ebook is for the use of anyone anywhere in the united states and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. you may copy it, give it away or re-use it under the terms\n",
            "of the project gutenberg license included with this ebook or online at\n",
            "www.gutenberg.org. if you are not located in the united states, you\n",
            "will have to check the laws of the country where you are located before\n",
            "using this ebook.\n",
            "\n",
            "** this is a copyrighted project gutenberg ebook, details below **\n",
            "**     please follow the copyright guidelines in this file.     **\n",
            "\n",
            "title: metamorphosis\n",
            "\n",
            "author: franz kafka\n",
            "\n",
            "translator: david wyllie\n",
            "\n",
            "release date: may 13, 2002 [ebook #5200]\n",
            "[most recently updated: may 20, 2012]\n",
            "\n",
            "language: english\n",
            "\n",
            "character set encoding: utf-8\n",
            "\n",
            "copyright (c) 2002 by david wyllie.\n",
            "\n",
            "*** start of the project gutenberg ebook metamorphosis ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "metamorphosis\n",
            "\n",
            "by franz kafka\n",
            "\n",
            "translated by david wyllie\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars: ' , len(chars))\n",
        "print('total chars: ' , chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTx0i8O6MUqI",
        "outputId": "a8f208aa-2daf-463c-b4a5-a8819cb184f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total chars:  62\n",
            "total chars:  ['\\n', ' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ç', '—', '’', '“', '”', '\\ufeff']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_indicies = dict((c, i) for i, c in enumerate(chars))\n",
        "indicies_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "xpe1Dl0BNSmC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "  sentences.append(text[i: i + maxlen])\n",
        "  next_chars.append(text[i + maxlen])\n",
        "\n",
        "print('nb sentences: ', len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lCtJ6NCNIiv",
        "outputId": "5cd5db11-1fdd-4d3e-f2ef-6e5cb323b4ca"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb sentences:  46123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[:3])\n",
        "print(next_chars[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XInqi6cSOj43",
        "outputId": "8813b2dc-348c-413b-d476-accfe5a0b75f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeffthe project gutenberg ebook of metamorp', 'e project gutenberg ebook of metamorphos', 'roject gutenberg ebook of metamorphosis,']\n",
            "['h', 'i', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, char_indicies[char]] = 1\n",
        "    y[i, char_indicies[next_chars[i]]] = 1"
      ],
      "metadata": {
        "id": "WLnWoAJ4OwOY"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(254, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(10*len(chars)))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "TuYHR2YiP4Bs"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(learning_rate = 0.01))"
      ],
      "metadata": {
        "id": "XSgnnoxKQ495"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size = 128, epochs = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFCKP4IqRreC",
        "outputId": "a892250c-4058-48d1-938f-19bfb484fb1c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "361/361 [==============================] - 5s 8ms/step - loss: 3.2047\n",
            "Epoch 2/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 1.9309\n",
            "Epoch 3/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 1.7068\n",
            "Epoch 4/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 1.5582\n",
            "Epoch 5/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 1.4369\n",
            "Epoch 6/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 1.3327\n",
            "Epoch 7/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 1.2337\n",
            "Epoch 8/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 1.1412\n",
            "Epoch 9/50\n",
            "361/361 [==============================] - 3s 9ms/step - loss: 1.0599\n",
            "Epoch 10/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.9800\n",
            "Epoch 11/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.9090\n",
            "Epoch 12/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.8374\n",
            "Epoch 13/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.7810\n",
            "Epoch 14/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.7215\n",
            "Epoch 15/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.6846\n",
            "Epoch 16/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.6462\n",
            "Epoch 17/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.6038\n",
            "Epoch 18/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.5735\n",
            "Epoch 19/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.5407\n",
            "Epoch 20/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.5159\n",
            "Epoch 21/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.4860\n",
            "Epoch 22/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.4646\n",
            "Epoch 23/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.4440\n",
            "Epoch 24/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.4262\n",
            "Epoch 25/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.4058\n",
            "Epoch 26/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.3883\n",
            "Epoch 27/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.3753\n",
            "Epoch 28/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.3642\n",
            "Epoch 29/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.3523\n",
            "Epoch 30/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.3312\n",
            "Epoch 31/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.3308\n",
            "Epoch 32/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.3194\n",
            "Epoch 33/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.3151\n",
            "Epoch 34/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.2979\n",
            "Epoch 35/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.2969\n",
            "Epoch 36/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.2938\n",
            "Epoch 37/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.2840\n",
            "Epoch 38/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.2716\n",
            "Epoch 39/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.2647\n",
            "Epoch 40/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.2564\n",
            "Epoch 41/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.2548\n",
            "Epoch 42/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.2492\n",
            "Epoch 43/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.2463\n",
            "Epoch 44/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.2409\n",
            "Epoch 45/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.2380\n",
            "Epoch 46/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.2235\n",
            "Epoch 47/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.2242\n",
            "Epoch 48/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.2221\n",
            "Epoch 49/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.2176\n",
            "Epoch 50/50\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.2197\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd0f50fe2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature = 1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)\n",
        "\n",
        "def generate_text(sentence, length, diversity):\n",
        "  generated = ''\n",
        "  generated += sentence\n",
        "  for i in range(length):\n",
        "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "      x_pred[0, t, char_indicies[char]] = 1.\n",
        "\n",
        "    preds = model.predict(x_pred, verbose = 0)[0]\n",
        "    next_index = sample(preds, diversity)\n",
        "    next_char = indicies_char[next_index]\n",
        "\n",
        "    generated += next_char\n",
        "    sentence = sentence[1:] + next_char\n",
        "  return generated\n"
      ],
      "metadata": {
        "id": "Jeg-vniLYIA-"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" the firts thing he wanted to do was to \"\n",
        "sentence = text[0: maxlen]\n",
        "\n",
        "print(generate_text(sentence, 30,0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh4yH-LFaLfs",
        "outputId": "6a3147af-5802-48e6-dbd9-55b2b5ba7145"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the firts thing he wanted to do was to do\n",
            "rose himself, and then thou\n"
          ]
        }
      ]
    }
  ]
}
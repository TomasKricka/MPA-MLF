{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr883cxr2w1g"
      },
      "source": [
        "# MPA-MLF, Lab 5 - Feedforward Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWKpUeA1J8Sv"
      },
      "source": [
        "These exercises are focused on dealing with neural networks. It is strongly recommended to use google collab for these pc labs. Why? Google collab offers a free GPU capacity to train machine learning models. Training NN on GPU can drastically speed up the training process. You can turn on the GPU accelerator in: Runtime -> Change runtime type -> GPU, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejOYhsl_KlHt"
      },
      "source": [
        "## Exercise 1 - XOR problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLfjemjJKuPV"
      },
      "source": [
        "During the last lecture, we saw that the single perceptron model with a step function could be used only for solving linearly-separable classification problems. Because of that, a single perceptron can not be trained to be able to behave like an XOR gate. To approximate the XOR gate using a neural network, we need to use the following structure:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7hCklzwNm_9"
      },
      "source": [
        "![nn.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyWI7oiCQsPT"
      },
      "source": [
        "The above structure contains three layers: two neurons in the input layer (blue), two in the hidden layer and one in the output layer (yellow). The input layer represents the identity functions (the outputs are equal to the inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBGB2Zq4CN0z"
      },
      "source": [
        "We will use *Keras* API to build and train our neural network. Keras is an open-source neural network library written in Python. It is designed to enable fast experimentation with deep neural networks and provides a high-level API for building and training neural networks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiMMyX7B2zUw"
      },
      "source": [
        "### 0. First import libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzC8HPME2pgP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnLbt_-U2_4Y"
      },
      "source": [
        "### 1. prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kwB40qi5cQr"
      },
      "source": [
        "In this part, the task would be to prepade our dataset, basically it is the logic table for *XOR* function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWLETf7k2wiY"
      },
      "outputs": [],
      "source": [
        "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "y = [0, 1, 1, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ5ZwSDU3Qho"
      },
      "source": [
        "### 2. Creating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Otl0iDM5lHm"
      },
      "source": [
        "To create a model of NN that is in the picture above, run the following cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpAah84r2vyw"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(2, input_dim=2, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoBvH8UQDM95"
      },
      "source": [
        "**Sequential** is a model type used in Keras for building feedforward neural networks. It is called \"sequential\" because the layers are stacked sequentially on top of each other, and the output of one layer is passed as input to the next layer.\n",
        "\n",
        "To create a sequential model, instantiate a Sequential object and then add layers to it using the **add()** method. There are many layers that Keras offers. We will use *Dense layer*\n",
        "\n",
        "**Dense layer** represents a fully connected layer, which means that every neuron in the layer is connected to every neuron in the previous layer. In each layer, we will specify an activation function and the number of neurons that layer contains. The input layer is not defined as a dense layer, but instead of that, we will specify the *input_dim* parameter in the layer that follows the input layer. *input_dim* parameter specifies the number of neurons in the input layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtNu4JiE3XVw"
      },
      "source": [
        "### 3. Compile the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHk2-s3V5_Hb"
      },
      "source": [
        "To compile yor model run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCKtEOAf3awX"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.8)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pf4-t6PGDEv"
      },
      "source": [
        "**keras.complile()** is used to configure the learning process before training the model. \n",
        "We need to specify 3 parameters:\n",
        "- *loss*, *optimizer* and *metrics*\n",
        "\n",
        "- as our loss function (error function/objective function), we will choose *binary_crossentropy* - loss function often used for binary classification\n",
        "\n",
        "- *optimizer* is optimization algorithm used for optimizing weights in our training process, we will choose *stochastic gradient descent* \n",
        "\n",
        "- *metrics* is metric user for model evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY0oJ_g13d7o"
      },
      "source": [
        "### 4. Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dX_p6mn4aoX"
      },
      "source": [
        "In the lecture, we talked about training the Multi-layer perceptron. The training process consists of the following steps:\n",
        "\n",
        "1. Weight initialization\n",
        "2. Forward Propagation\n",
        "3. Compute Loss\n",
        "4. Backpropagation\n",
        "5. Update Weights\n",
        "6. Repeat 2->6 until maximum epochs are reached\n",
        "\n",
        "When training a machine learning model, the training data is usually divided into batches (parts), and the model updates its weights after processing each batch. The batch size determines how many training examples are included in each batch. \n",
        "\n",
        "For example, we have 10,000 training examples and a batch size of 100. In this case, the training data would be divided into 100 batches of 100 examples each. During training, the model would process each batch, calculate the loss or error, and update its weights based on the average of the errors in that batch. In other words, if we batch equal to 1. we will update the weights 10 000 times. If we have batch size == 100, we will update the weights only 100 times "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhlzz2hr0n5Y"
      },
      "source": [
        "To train your model, run the following line of the code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE7eNdJi3gbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "826e97ed-e034-4d90-9e6a-582fe03b9953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "1/1 [==============================] - 1s 586ms/step - loss: 0.7030 - accuracy: 0.5000\n",
            "Epoch 2/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7001 - accuracy: 0.5000\n",
            "Epoch 3/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6985 - accuracy: 0.2500\n",
            "Epoch 4/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6977 - accuracy: 0.2500\n",
            "Epoch 5/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6973 - accuracy: 0.2500\n",
            "Epoch 6/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6970 - accuracy: 0.2500\n",
            "Epoch 7/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 8/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6967 - accuracy: 0.5000\n",
            "Epoch 9/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6966 - accuracy: 0.5000\n",
            "Epoch 10/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6965 - accuracy: 0.5000\n",
            "Epoch 11/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 12/400\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.6963 - accuracy: 0.5000\n",
            "Epoch 13/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6962 - accuracy: 0.5000\n",
            "Epoch 14/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 15/400\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 16/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6960 - accuracy: 0.5000\n",
            "Epoch 17/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 18/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 19/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 20/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 21/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 22/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 23/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 24/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 25/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 26/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 27/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 28/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 29/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 30/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 31/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 32/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 33/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 34/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 35/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 36/400\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 37/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 38/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 39/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 40/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 41/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 42/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 43/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 44/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 45/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 46/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 47/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 48/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 49/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 50/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 51/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 52/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 53/400\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 54/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 55/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 56/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 57/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 58/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 59/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 60/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 61/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 62/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 63/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 64/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 65/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 66/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 67/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 68/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 69/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 70/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 71/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 72/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 73/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 74/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 75/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 76/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 77/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 78/400\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 79/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 80/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 81/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 82/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 83/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 84/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 85/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 86/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 87/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 88/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 89/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 90/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 91/400\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 92/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 93/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 94/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 95/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 96/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 97/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 98/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 99/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 100/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 101/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 102/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 103/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 104/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 105/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 106/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 107/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 108/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 109/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 110/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 111/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 112/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 113/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 114/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 115/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 116/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 117/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 118/400\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 119/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 120/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 121/400\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 122/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 123/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 124/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 125/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 126/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 127/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 128/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 129/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 130/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 131/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 132/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 133/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 134/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 135/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 136/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 137/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 138/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 139/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 140/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 141/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 142/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 143/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 144/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 145/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 146/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 147/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 148/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 149/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 150/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 151/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 152/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 153/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 154/400\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 155/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 156/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 157/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 158/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 159/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 160/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 161/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 162/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 163/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 164/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 165/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 166/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 167/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 168/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 169/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 170/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 171/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 172/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 173/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 174/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 175/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 176/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 177/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 178/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 179/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 180/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 181/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 182/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 183/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 184/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 185/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 186/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 187/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 188/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 189/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 190/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 191/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 192/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 193/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 194/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 195/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 196/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 197/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 198/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 199/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 200/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 201/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 202/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 203/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 204/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 205/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 206/400\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 207/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 208/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 209/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 210/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 211/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 212/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 213/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 214/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 215/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 216/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 217/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 218/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 219/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 220/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 221/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 222/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 223/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 224/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 225/400\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 226/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 227/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 228/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 229/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 230/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 231/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 232/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 233/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 234/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 235/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 236/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 237/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 238/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 239/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 240/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 241/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 242/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 243/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 244/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 245/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 246/400\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 247/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 248/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 249/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 250/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 251/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 252/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 253/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 254/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 255/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 256/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 257/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 258/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 259/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 260/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 261/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 262/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 263/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 264/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 265/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 266/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 267/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 268/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 269/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 270/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 271/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 272/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 273/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 274/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 275/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 276/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 277/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 278/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 279/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 280/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 281/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 282/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 283/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 284/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 285/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 286/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 287/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 288/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 289/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 290/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 291/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 292/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 293/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 294/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 295/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 296/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 297/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 298/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 299/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 300/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 301/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 302/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 303/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 304/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 305/400\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 306/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 307/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 308/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 309/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 310/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 311/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 312/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 313/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 314/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 315/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 316/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 317/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 318/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 319/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 320/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 321/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 322/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 323/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 324/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 325/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 326/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 327/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 328/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 329/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 330/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 331/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 332/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 333/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 334/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 335/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 336/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 337/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 338/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 339/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 340/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 341/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 342/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 343/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 344/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 345/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 346/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 347/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 348/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 349/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 350/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 351/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 352/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 353/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 354/400\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 355/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 356/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 357/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 358/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 359/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 360/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 361/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 362/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 363/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 364/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 365/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 366/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 367/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 368/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 369/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 370/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 371/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 372/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 373/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 374/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 375/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 376/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 377/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 378/400\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 379/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 380/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 381/400\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 382/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 383/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 384/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 385/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 386/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 387/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 388/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 389/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 390/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 391/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 392/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 393/400\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 394/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 395/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 396/400\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 397/400\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 398/400\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 399/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 400/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X, y, epochs=400, batch_size=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJNcrzuu02Kn"
      },
      "source": [
        "the method **.fit()**, is used to train the model. We can see that it takes several input parameters:\n",
        " - *X* - input data\n",
        " - *y* - label for the input data\n",
        " - *epochs* number of training epochs (iterations)\n",
        " - *batch_size* - number of samples in each batch\n",
        " - *verbose* - set verbose parameter to see the progress of loss and metrics during the training epochs\n",
        "\n",
        "These are not the only parameters the .fit() method can take. Check official documentation: https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "We will set the output of our .fit() function to variable *history*, where the loss and other metrics defined above in the .compile() function during the training are saved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1M4VvU83jXY"
      },
      "source": [
        "### 5. Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdJl6X-61gL4"
      },
      "source": [
        "Out training process is finished. To evaluate the performance of our model on test data, tun the following cell of the code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbM0bLm83iiQ",
        "outputId": "faa5ebb2-1537-4546-f444-0d9e6cdb21ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 126ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Accuracy: 50.00\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(X, y, verbose=1)\n",
        "print('Accuracy: {:.2f}'.format(accuracy*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYloVKFcUcYP"
      },
      "source": [
        "### 6. Model predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEO2iQHnUjDo",
        "outputId": "2be6f53e-fd03-487a-83e9-cc6b76fe211f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Data sample is [0, 0], prediction from model [[0.5033743]], ground_truth 0\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Data sample is [0, 1], prediction from model [[0.4992955]], ground_truth 1\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Data sample is [1, 0], prediction from model [[0.50047404]], ground_truth 1\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Data sample is [1, 1], prediction from model [[0.49641716]], ground_truth 0\n"
          ]
        }
      ],
      "source": [
        "for id_x, data_sample in enumerate(X):\n",
        "  prediction = model.predict([data_sample])\n",
        "  print(f\"Data sample is {data_sample}, prediction from model {prediction}, ground_truth {y[id_x]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znRHpDEbABvg"
      },
      "source": [
        "### 7. Display loss function during the training process and acuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "zmFOaJHA41Tb",
        "outputId": "3a382c2a-cae8-4236-9c54-15e946d3ffa6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('n epochs')\n",
        "plt.ylabel('loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK40q-xmHvIr"
      },
      "source": [
        "### TASK:\n",
        "\n",
        "In this part of the exercise, the task would be to play around with the code above to see the influence of hyperparameters.\n",
        "\n",
        "As we know from the lecture, neural networks contain two types of parameters:\n",
        "  1. **Learnable parameters** - *weights* and *biases*. these parameters are adjusted in the training process.  \n",
        "  2. **Non-learnable parameters (hyperparameters)** - learning_rate, number_of_neurons, number_of_layers, number_of_epochs, type of activation functions in the neurons.., basically any user-defined setting is considered to be hyperparameter\n",
        "\n",
        "\n",
        "Change the following parameters: \n",
        "- number of epochs\n",
        "- learning_rate\n",
        "- activation functions in layers, \n",
        "- batch_size,\n",
        "- verbose,\n",
        "- number of neurons in the hidden layer\n",
        "\n",
        "Moreover, see the influence on the training process and results.\n",
        "\n",
        "**Note: Every time we change some hyper-parameters, do not forget to compile the model, to initialize the learnable parameters again**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbMYYFtl8lhd"
      },
      "source": [
        "## Exercise 2 - Congressional Voting Data\n",
        "\n",
        "In the attached dataset, results from congressional voting can be found. Your task is to train a model that can recognize that the politician is *republican* or *democrat* based on voting results. We would follow the general machine learning steps that were described in the lecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCvGPSYX8pbf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSoCAe_gAAP5"
      },
      "source": [
        "### 1. Loading dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm8Kj3sJiLAx"
      },
      "source": [
        "**First mount your google drive to google colab file.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "AqSVkJc8_f4R"
      },
      "outputs": [],
      "source": [
        "path_to_dataset = 'drive/MyDrive/MLF/pc5/voting_complete.csv' # change the PATH\n",
        "pd_dataset = pd.read_csv(path_to_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-9SH0_oXS8YL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc2b4c7-99d1-4b12-94f1-a60f42b319a0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "ZHxyq2C5_vJh",
        "outputId": "56c57fae-eddd-4634-fdf4-c27f7fe8aa20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  Class Name handicapped-infants water-project-cost-sharing  \\\n",
              "0             0  republican                   n                          y   \n",
              "1             1  republican                   n                          y   \n",
              "2             2    democrat                   ?                          y   \n",
              "3             3    democrat                   n                          y   \n",
              "4             4    democrat                   y                          y   \n",
              "..          ...         ...                 ...                        ...   \n",
              "430         430  republican                   n                          n   \n",
              "431         431    democrat                   n                          n   \n",
              "432         432  republican                   n                          ?   \n",
              "433         433  republican                   n                          n   \n",
              "434         434  republican                   n                          y   \n",
              "\n",
              "    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n",
              "0                                   n                    y               y   \n",
              "1                                   n                    y               y   \n",
              "2                                   y                    ?               y   \n",
              "3                                   y                    n               ?   \n",
              "4                                   y                    n               y   \n",
              "..                                ...                  ...             ...   \n",
              "430                                 y                    y               y   \n",
              "431                                 y                    n               n   \n",
              "432                                 n                    y               y   \n",
              "433                                 n                    y               y   \n",
              "434                                 n                    y               y   \n",
              "\n",
              "    religious-groups-in-schools anti-satellite-test-ban  \\\n",
              "0                             y                       n   \n",
              "1                             y                       n   \n",
              "2                             y                       n   \n",
              "3                             y                       n   \n",
              "4                             y                       n   \n",
              "..                          ...                     ...   \n",
              "430                           y                       n   \n",
              "431                           n                       y   \n",
              "432                           y                       n   \n",
              "433                           y                       ?   \n",
              "434                           y                       n   \n",
              "\n",
              "    aid-to-nicaraguan-contras mx-missile immigration  \\\n",
              "0                           n          n           y   \n",
              "1                           n          n           n   \n",
              "2                           n          n           n   \n",
              "3                           n          n           n   \n",
              "4                           n          n           n   \n",
              "..                        ...        ...         ...   \n",
              "430                         n          y           y   \n",
              "431                         y          y           y   \n",
              "432                         n          n           n   \n",
              "433                         ?          ?           ?   \n",
              "434                         n          n           y   \n",
              "\n",
              "    synfuels-corporation-cutback education-spending superfund-right-to-sue  \\\n",
              "0                              ?                  y                      y   \n",
              "1                              n                  y                      y   \n",
              "2                              y                  n                      y   \n",
              "3                              y                  n                      y   \n",
              "4                              y                  ?                      y   \n",
              "..                           ...                ...                    ...   \n",
              "430                            n                  y                      y   \n",
              "431                            n                  n                      n   \n",
              "432                            y                  y                      y   \n",
              "433                            n                  y                      y   \n",
              "434                            n                  y                      y   \n",
              "\n",
              "    crime duty-free-exports export-administration-act-south-africa  \n",
              "0       y                 n                                      y  \n",
              "1       y                 n                                      ?  \n",
              "2       y                 n                                      n  \n",
              "3       n                 n                                      y  \n",
              "4       y                 y                                      y  \n",
              "..    ...               ...                                    ...  \n",
              "430     y                 n                                      y  \n",
              "431     n                 n                                      y  \n",
              "432     y                 n                                      y  \n",
              "433     y                 n                                      y  \n",
              "434     y                 ?                                      n  \n",
              "\n",
              "[435 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d175e4a-0ff6-4fbc-94f7-dcfabf67a82d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Class Name</th>\n",
              "      <th>handicapped-infants</th>\n",
              "      <th>water-project-cost-sharing</th>\n",
              "      <th>adoption-of-the-budget-resolution</th>\n",
              "      <th>physician-fee-freeze</th>\n",
              "      <th>el-salvador-aid</th>\n",
              "      <th>religious-groups-in-schools</th>\n",
              "      <th>anti-satellite-test-ban</th>\n",
              "      <th>aid-to-nicaraguan-contras</th>\n",
              "      <th>mx-missile</th>\n",
              "      <th>immigration</th>\n",
              "      <th>synfuels-corporation-cutback</th>\n",
              "      <th>education-spending</th>\n",
              "      <th>superfund-right-to-sue</th>\n",
              "      <th>crime</th>\n",
              "      <th>duty-free-exports</th>\n",
              "      <th>export-administration-act-south-africa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>republican</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>republican</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>democrat</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>democrat</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>democrat</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>430</td>\n",
              "      <td>republican</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>431</td>\n",
              "      <td>democrat</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>432</td>\n",
              "      <td>republican</td>\n",
              "      <td>n</td>\n",
              "      <td>?</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>433</td>\n",
              "      <td>republican</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>434</td>\n",
              "      <td>republican</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>435 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d175e4a-0ff6-4fbc-94f7-dcfabf67a82d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d175e4a-0ff6-4fbc-94f7-dcfabf67a82d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d175e4a-0ff6-4fbc-94f7-dcfabf67a82d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "pd_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrHZUFV-AEYh"
      },
      "source": [
        "### 2. Train/Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5Odr83IAcYP"
      },
      "source": [
        "Fistlty we need to split our dataset into train and test. We will use 80% of dataset as our trainset and 20% od dataset as our testset. You can use functions included in *keras*, *scikit-learn*, or you can write your own:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "24w7ksCcAddN"
      },
      "outputs": [],
      "source": [
        "# define a function for train and test split\n",
        "\n",
        "def train_test_split(pd_data: pd.DataFrame, test_ratio: float = 0.2) -> tuple:\n",
        "    pd_dataset = pd_data.copy()\n",
        "    pd_dataset = pd_dataset[pd_dataset.columns[1:]]\n",
        "    index = np.arange(len(pd_dataset))\n",
        "    index = np.random.permutation(index)\n",
        "    train_ammount = int(len(index)*test_ratio)\n",
        "    train_ids = index[train_ammount:]\n",
        "    test_ids = index[:train_ammount]\n",
        "    \n",
        "    train_dataset = pd_dataset[pd_dataset.index.isin(train_ids)].reset_index()\n",
        "    test_dataset = pd_dataset[pd_dataset.index.isin(test_ids)].reset_index()\n",
        "    \n",
        "    train_dataset = train_dataset[train_dataset.columns[1:]]\n",
        "    test_dataset = test_dataset[test_dataset.columns[1:]]\n",
        "\n",
        "    return train_dataset[train_dataset.columns[1:]], train_dataset[train_dataset.columns[0]], test_dataset[test_dataset.columns[1:]], test_dataset[test_dataset.columns[0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "R1FOBHIe_76o"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test = train_test_split(pd_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1aUQ2K-BGZ5"
      },
      "source": [
        "### 3. Data examination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUXBgnYdgH7T"
      },
      "source": [
        "The task would be to examine the dataset. Check:\n",
        "\n",
        "1. Is it a classification of regression task?\n",
        "2. How many data samples do we have?\n",
        "3. How many features do we have?  \n",
        "4. What data types do we have in our dataset?\n",
        "5. Are there any missing values?\n",
        "6. How many labels do we have? \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "0pKswr1YhMsS",
        "outputId": "0403ca8a-2344-47e5-b919-a092b3a1e0a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    handicapped-infants water-project-cost-sharing  \\\n",
              "0                     n                          y   \n",
              "1                     n                          y   \n",
              "2                     ?                          y   \n",
              "3                     y                          y   \n",
              "4                     n                          y   \n",
              "..                  ...                        ...   \n",
              "343                   ?                          ?   \n",
              "344                   y                          n   \n",
              "345                   n                          n   \n",
              "346                   n                          n   \n",
              "347                   n                          n   \n",
              "\n",
              "    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n",
              "0                                   n                    y               y   \n",
              "1                                   n                    y               y   \n",
              "2                                   y                    ?               y   \n",
              "3                                   y                    n               y   \n",
              "4                                   y                    n               y   \n",
              "..                                ...                  ...             ...   \n",
              "343                                 ?                    n               n   \n",
              "344                                 y                    n               ?   \n",
              "345                                 y                    y               y   \n",
              "346                                 y                    n               n   \n",
              "347                                 n                    y               y   \n",
              "\n",
              "    religious-groups-in-schools anti-satellite-test-ban  \\\n",
              "0                             y                       n   \n",
              "1                             y                       n   \n",
              "2                             y                       n   \n",
              "3                             y                       n   \n",
              "4                             y                       n   \n",
              "..                          ...                     ...   \n",
              "343                           n                       y   \n",
              "344                           n                       y   \n",
              "345                           y                       n   \n",
              "346                           n                       y   \n",
              "347                           y                       ?   \n",
              "\n",
              "    aid-to-nicaraguan-contras mx-missile immigration  \\\n",
              "0                           n          n           y   \n",
              "1                           n          n           n   \n",
              "2                           n          n           n   \n",
              "3                           n          n           n   \n",
              "4                           n          n           n   \n",
              "..                        ...        ...         ...   \n",
              "343                         y          y           y   \n",
              "344                         y          y           y   \n",
              "345                         n          y           y   \n",
              "346                         y          y           y   \n",
              "347                         ?          ?           ?   \n",
              "\n",
              "    synfuels-corporation-cutback education-spending superfund-right-to-sue  \\\n",
              "0                              ?                  y                      y   \n",
              "1                              n                  y                      y   \n",
              "2                              y                  n                      y   \n",
              "3                              y                  ?                      y   \n",
              "4                              n                  n                      y   \n",
              "..                           ...                ...                    ...   \n",
              "343                            n                  n                      y   \n",
              "344                            n                  y                      n   \n",
              "345                            n                  y                      y   \n",
              "346                            n                  n                      n   \n",
              "347                            n                  y                      y   \n",
              "\n",
              "    crime duty-free-exports export-administration-act-south-africa  \n",
              "0       y                 n                                      y  \n",
              "1       y                 n                                      ?  \n",
              "2       y                 n                                      n  \n",
              "3       y                 y                                      y  \n",
              "4       y                 y                                      y  \n",
              "..    ...               ...                                    ...  \n",
              "343     n                 y                                      y  \n",
              "344     ?                 y                                      y  \n",
              "345     y                 n                                      y  \n",
              "346     n                 n                                      y  \n",
              "347     y                 n                                      y  \n",
              "\n",
              "[348 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11bfa57f-84f2-4b39-a27f-e870004dbcd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handicapped-infants</th>\n",
              "      <th>water-project-cost-sharing</th>\n",
              "      <th>adoption-of-the-budget-resolution</th>\n",
              "      <th>physician-fee-freeze</th>\n",
              "      <th>el-salvador-aid</th>\n",
              "      <th>religious-groups-in-schools</th>\n",
              "      <th>anti-satellite-test-ban</th>\n",
              "      <th>aid-to-nicaraguan-contras</th>\n",
              "      <th>mx-missile</th>\n",
              "      <th>immigration</th>\n",
              "      <th>synfuels-corporation-cutback</th>\n",
              "      <th>education-spending</th>\n",
              "      <th>superfund-right-to-sue</th>\n",
              "      <th>crime</th>\n",
              "      <th>duty-free-exports</th>\n",
              "      <th>export-administration-act-south-africa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>?</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>348 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11bfa57f-84f2-4b39-a27f-e870004dbcd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11bfa57f-84f2-4b39-a27f-e870004dbcd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11bfa57f-84f2-4b39-a27f-e870004dbcd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTxf4gaqrLge"
      },
      "source": [
        "### 4. Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcJ41-OtrOah"
      },
      "source": [
        "When you preprocess your traing data, do not forget that you need to apply the same preprocessing also for your test set. For example: If you decide to delete some columns in your train set, you have to delete the same columns in your test set. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWPwLG1EWiQ"
      },
      "source": [
        "Possible preprocessing steps (try several and see the influence of your preprocessing on your results)\n",
        " - Replace missing values with any data imputation technique ( for example, the most occurring value in the column), then perform one-hot encoding or label encoding of your data\n",
        " - Consider the missing value to be the third category 'unknown' and then perform one-hot encoding or label encoding\n",
        "\n",
        "The target value also has to be encoded. This can be done by one-hot encoding or label encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "W66ufwuigEcG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "74f61b65-8a6d-424e-c798-0c9f64dfec2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     handicapped-infants_?  handicapped-infants_n  handicapped-infants_y  \\\n",
              "0                        0                      1                      0   \n",
              "1                        0                      1                      0   \n",
              "2                        1                      0                      0   \n",
              "3                        0                      0                      1   \n",
              "4                        0                      1                      0   \n",
              "..                     ...                    ...                    ...   \n",
              "343                      1                      0                      0   \n",
              "344                      0                      0                      1   \n",
              "345                      0                      1                      0   \n",
              "346                      0                      1                      0   \n",
              "347                      0                      1                      0   \n",
              "\n",
              "     water-project-cost-sharing_?  water-project-cost-sharing_n  \\\n",
              "0                               0                             0   \n",
              "1                               0                             0   \n",
              "2                               0                             0   \n",
              "3                               0                             0   \n",
              "4                               0                             0   \n",
              "..                            ...                           ...   \n",
              "343                             1                             0   \n",
              "344                             0                             1   \n",
              "345                             0                             1   \n",
              "346                             0                             1   \n",
              "347                             0                             1   \n",
              "\n",
              "     water-project-cost-sharing_y  adoption-of-the-budget-resolution_?  \\\n",
              "0                               1                                    0   \n",
              "1                               1                                    0   \n",
              "2                               1                                    0   \n",
              "3                               1                                    0   \n",
              "4                               1                                    0   \n",
              "..                            ...                                  ...   \n",
              "343                             0                                    1   \n",
              "344                             0                                    0   \n",
              "345                             0                                    0   \n",
              "346                             0                                    0   \n",
              "347                             0                                    0   \n",
              "\n",
              "     adoption-of-the-budget-resolution_n  adoption-of-the-budget-resolution_y  \\\n",
              "0                                      1                                    0   \n",
              "1                                      1                                    0   \n",
              "2                                      0                                    1   \n",
              "3                                      0                                    1   \n",
              "4                                      0                                    1   \n",
              "..                                   ...                                  ...   \n",
              "343                                    0                                    0   \n",
              "344                                    0                                    1   \n",
              "345                                    0                                    1   \n",
              "346                                    0                                    1   \n",
              "347                                    1                                    0   \n",
              "\n",
              "     physician-fee-freeze_?  ...  superfund-right-to-sue_y  crime_?  crime_n  \\\n",
              "0                         0  ...                         1        0        0   \n",
              "1                         0  ...                         1        0        0   \n",
              "2                         1  ...                         1        0        0   \n",
              "3                         0  ...                         1        0        0   \n",
              "4                         0  ...                         1        0        0   \n",
              "..                      ...  ...                       ...      ...      ...   \n",
              "343                       0  ...                         1        0        1   \n",
              "344                       0  ...                         0        1        0   \n",
              "345                       0  ...                         1        0        0   \n",
              "346                       0  ...                         0        0        1   \n",
              "347                       0  ...                         1        0        0   \n",
              "\n",
              "     crime_y  duty-free-exports_?  duty-free-exports_n  duty-free-exports_y  \\\n",
              "0          1                    0                    1                    0   \n",
              "1          1                    0                    1                    0   \n",
              "2          1                    0                    1                    0   \n",
              "3          1                    0                    0                    1   \n",
              "4          1                    0                    0                    1   \n",
              "..       ...                  ...                  ...                  ...   \n",
              "343        0                    0                    0                    1   \n",
              "344        0                    0                    0                    1   \n",
              "345        1                    0                    1                    0   \n",
              "346        0                    0                    1                    0   \n",
              "347        1                    0                    1                    0   \n",
              "\n",
              "     export-administration-act-south-africa_?  \\\n",
              "0                                           0   \n",
              "1                                           1   \n",
              "2                                           0   \n",
              "3                                           0   \n",
              "4                                           0   \n",
              "..                                        ...   \n",
              "343                                         0   \n",
              "344                                         0   \n",
              "345                                         0   \n",
              "346                                         0   \n",
              "347                                         0   \n",
              "\n",
              "     export-administration-act-south-africa_n  \\\n",
              "0                                           0   \n",
              "1                                           0   \n",
              "2                                           1   \n",
              "3                                           0   \n",
              "4                                           0   \n",
              "..                                        ...   \n",
              "343                                         0   \n",
              "344                                         0   \n",
              "345                                         0   \n",
              "346                                         0   \n",
              "347                                         0   \n",
              "\n",
              "     export-administration-act-south-africa_y  \n",
              "0                                           1  \n",
              "1                                           0  \n",
              "2                                           0  \n",
              "3                                           1  \n",
              "4                                           1  \n",
              "..                                        ...  \n",
              "343                                         1  \n",
              "344                                         1  \n",
              "345                                         1  \n",
              "346                                         1  \n",
              "347                                         1  \n",
              "\n",
              "[348 rows x 48 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-faa19a73-50c7-4fdc-a9ff-46b3fd760f6e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handicapped-infants_?</th>\n",
              "      <th>handicapped-infants_n</th>\n",
              "      <th>handicapped-infants_y</th>\n",
              "      <th>water-project-cost-sharing_?</th>\n",
              "      <th>water-project-cost-sharing_n</th>\n",
              "      <th>water-project-cost-sharing_y</th>\n",
              "      <th>adoption-of-the-budget-resolution_?</th>\n",
              "      <th>adoption-of-the-budget-resolution_n</th>\n",
              "      <th>adoption-of-the-budget-resolution_y</th>\n",
              "      <th>physician-fee-freeze_?</th>\n",
              "      <th>...</th>\n",
              "      <th>superfund-right-to-sue_y</th>\n",
              "      <th>crime_?</th>\n",
              "      <th>crime_n</th>\n",
              "      <th>crime_y</th>\n",
              "      <th>duty-free-exports_?</th>\n",
              "      <th>duty-free-exports_n</th>\n",
              "      <th>duty-free-exports_y</th>\n",
              "      <th>export-administration-act-south-africa_?</th>\n",
              "      <th>export-administration-act-south-africa_n</th>\n",
              "      <th>export-administration-act-south-africa_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>348 rows × 48 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faa19a73-50c7-4fdc-a9ff-46b3fd760f6e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-faa19a73-50c7-4fdc-a9ff-46b3fd760f6e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-faa19a73-50c7-4fdc-a9ff-46b3fd760f6e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "#WRITE YOUR CODE HERE\n",
        "x = pd.get_dummies(x_train)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "DvulEffMsfbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ce023c-8ef9-4170-8dd4-aad2ef97b24b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "343    0\n",
              "344    0\n",
              "345    1\n",
              "346    0\n",
              "347    1\n",
              "Name: Class Name, Length: 348, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "#WRITE YOUR CODE HERE\n",
        "y_train = y_train.replace('republican',1)\n",
        "y = y_train.replace('democrat', 0)\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdmHivmkuGZy"
      },
      "source": [
        "### 5. Creating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4FBQOiJGGDa"
      },
      "source": [
        "1. Create your model using alteast one hidden layer. \n",
        "\n",
        "*hint: do not create too complex models, this is a very simple task, so it would be enought to use just few neurons in the hidden layers*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "tUGDXUEFs093"
      },
      "outputs": [],
      "source": [
        "# WRITE YOU CODE HERE\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(2, input_dim=48, activation='sigmoid'))\n",
        "model2.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87ZBo4g5Klno"
      },
      "source": [
        "2. Check what *model.summary()* does"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "s2lwjf4Yu1Wh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1619cea1-08ca-46cb-cbbe-6e37f9233343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 2)                 98        \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101\n",
            "Trainable params: 101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# WRITE YOU CODE HERE\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugHf36DoKrHT"
      },
      "source": [
        "3. Compile the model, choose a suitable loss function, choose gradient to descend optimizer and specify the learning rate, and choose accuracy as our metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "ejSrDLDDu1w4"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "optimizer2 = tf.keras.optimizers.SGD(learning_rate=0.9)\n",
        "model2.compile(loss='binary_crossentropy', optimizer=optimizer2, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hc9SWvcMRzX"
      },
      "source": [
        "4. Train the model. Specify the number of epochs and batch size. Now is the time to create a validation dataset. Set 20% of dataset to be a validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "6UjQuXXCMEu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bfd0661-cbdf-4211-f496-6d4eed7f9649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 3ms/step - loss: 0.5441 - accuracy: 0.8017\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.9310\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.9540\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9626\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.1333 - accuracy: 0.9569\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9684\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 0.0974 - accuracy: 0.9684\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 0.9655\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9741\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 0.9684\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9655\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9713\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9713\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9741\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9770\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9770\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9856\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9713\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9828\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9856\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9799\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9799\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9856\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9828\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9770\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9856\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9856\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9799\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9885\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9856\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9828\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9828\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9799\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9799\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9914\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9885\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9799\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9914\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9885\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9828\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.9856\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 1s 59ms/step - loss: 0.0279 - accuracy: 0.9943\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9856\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9885\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0278 - accuracy: 0.9914\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 1s 59ms/step - loss: 0.0310 - accuracy: 0.9856\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9885\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0283 - accuracy: 0.9885\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 1s 63ms/step - loss: 0.0280 - accuracy: 0.9885\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9799\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9914\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9885\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9885\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 0.9856\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.9885\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9943\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9885\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9885\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9828\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.9828\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 1s 59ms/step - loss: 0.0224 - accuracy: 0.9914\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9856\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9943\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 1s 54ms/step - loss: 0.0212 - accuracy: 0.9943\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.9856\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 1s 4ms/step - loss: 0.0232 - accuracy: 0.9914\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 1s 54ms/step - loss: 0.0214 - accuracy: 0.9914\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9914\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9943\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9914\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 0.9856\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9914\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9885\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9914\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9914\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9885\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9914\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.9943\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0221 - accuracy: 0.9885\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9971\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9885\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0217 - accuracy: 0.9914\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 1s 61ms/step - loss: 0.0178 - accuracy: 0.9971\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9885\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0235 - accuracy: 0.9885\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0230 - accuracy: 0.9943\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9943\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 1s 55ms/step - loss: 0.0294 - accuracy: 0.9885\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 1s 54ms/step - loss: 0.0250 - accuracy: 0.9828\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.9971\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.9885\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0176 - accuracy: 0.9943\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 1s 55ms/step - loss: 0.0238 - accuracy: 0.9914\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9943\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9914\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0208 - accuracy: 0.9914\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9914\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.9914\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9971\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9943\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9971\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 0.9943\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9971\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9856\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9943\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9943\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9914\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 1s 58ms/step - loss: 0.0308 - accuracy: 0.9799\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9885\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9943\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9914\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9943\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 0.9885\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9914\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9943\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9914\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9971\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0153 - accuracy: 0.9971\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 1s 61ms/step - loss: 0.0197 - accuracy: 0.9914\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9971\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9971\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9943\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9914\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9943\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9943\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.9914\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9971\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9943\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0176 - accuracy: 0.9885\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0179 - accuracy: 0.9885\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0153 - accuracy: 0.9943\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9943\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9914\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 1s 3ms/step - loss: 0.0111 - accuracy: 0.9971\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0119 - accuracy: 0.9943\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9914\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9971\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0269 - accuracy: 0.9828\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9971\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9914\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9914\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 0.9971\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0137 - accuracy: 0.9943\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0118 - accuracy: 0.9971\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9971\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9943\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0113 - accuracy: 0.9971\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0175 - accuracy: 0.9943\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9943\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9971\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9943\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0113 - accuracy: 0.9943\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9914\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0142 - accuracy: 0.9914\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0141 - accuracy: 0.9943\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9943\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 1s 5ms/step - loss: 0.0134 - accuracy: 0.9943\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0131 - accuracy: 0.9943\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9943\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9971\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0107 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0113 - accuracy: 0.9971\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9943\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9971\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0148 - accuracy: 0.9914\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 1s 54ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9971\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9943\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9971\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9971\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9971\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9971\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9943\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9914\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9971\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9971\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9943\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9914\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 1s 58ms/step - loss: 0.0116 - accuracy: 0.9971\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0123 - accuracy: 0.9971\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9943\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9943\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9971\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9856\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 1s 63ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0160 - accuracy: 0.9971\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9971\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9971\n"
          ]
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "history2 = model2.fit(x, y, epochs=200, batch_size=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQMbJKL8KHeL"
      },
      "source": [
        "### 7. Model Evaluation \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzqLTyNOMtkG"
      },
      "source": [
        "1. First, apply the same preprocessing you did to train set to test set also"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "fwPbro7dKVZJ"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "x_train = pd.get_dummies(x)\n",
        "y_train1 = y.replace('republican',1)\n",
        "y_train = y_train1.replace('democrat', 0)\n",
        "\n",
        "#x_train\n",
        "#y_train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE34DAnkM7jM"
      },
      "source": [
        "2. Evaluate the model, print final accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "kmmp_9vPwaBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3493903d-8f63-47d2-c958-43bed6fe3df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 1s 92ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Accuracy: 100.00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.006519730668514967"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "\n",
        "loss, accuracy = model2.evaluate(x_train, y_train, verbose=1)\n",
        "print('Accuracy: {:.2f}'.format(accuracy*100))\n",
        "\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#for id_x, data_sample in enumerate(x):\n",
        "#  prediction2 = model2.predict([data_sample])\n",
        "#  print(f\"Data sample is {data_sample}, prediction from model {prediction2}, ground_truth {y[id_x]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "YVX016_2cxAc",
        "outputId": "9f89866d-a360-466a-e174-ebc46171806d"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 48) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48), dtype=tf.float32, name='dense_24_input'), name='dense_24_input', description=\"created by layer 'dense_24_input'\"), but it was called on an input with incompatible shape (None,).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "handicapped-infants_?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-144-887a586cc158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mprediction2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data sample is {data_sample}, prediction from model {prediction2}, ground_truth {y[id_x]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/input_spec.py\", line 250, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_12' (type Sequential).\n    \n    Input 0 of layer \"dense_24\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential_12' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=string)\n      • training=False\n      • mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOTKHtFsNEZV"
      },
      "source": [
        "3. Plot loss and validation loss depending on the training epochs into one graph. In another graph, plot accuracy and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "1SAkMeD4yA5x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "6d9c232c-fadc-48f1-ec51-ec199214eba8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "plt.figure()\n",
        "plt.plot(history2.history['loss'])\n",
        "plt.plot(history2.history['accuracy'])\n",
        "plt.xlabel('n epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history2.history['loss'])\n",
        "plt.plot(history2.history['accuracy'])\n",
        "plt.xlabel('n epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU-4VJsh0Z_1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}